{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "111faf70-fbc7-49b2-b406-9661363fbeab",
   "metadata": {},
   "source": [
    "---  \n",
    "layout: post  \n",
    "current: post  \n",
    "cover:  assets/built/images/GradientDescent.png  \n",
    "navigation: True  \n",
    "title: GradientDescent   \n",
    "date: 2023-03-10 00:00:00 +0900  \n",
    "tags: [exitem,TIL]  \n",
    "class: post-template  \n",
    "subclass: 'post tag-python'  \n",
    "author: chanp5660  \n",
    "---  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e780de-4ed9-4dfb-86d5-592a07c24a30",
   "metadata": {},
   "source": [
    "# Gradient Descent란?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e804209-e07d-4f5a-8da2-a613312a3eb3",
   "metadata": {},
   "source": [
    "- 경사 하강법;Gradient Descent 는 머신러닝에서 가장 기본적인 **최적화 알고리즘** 중 하나입니다.\n",
    "- 주어진 비용 함수(cost function)의 값이 최소화되는 가중치(weight)와 편향(bias)를 찾는데 사용됩니다.\n",
    "- 경사 하강법은 각 가중치와 편향의 기울기(gradient)를 계산하여 이 값이 0이 되는 지점을 찾습니다.\n",
    "- 핵심 아이디어는 **비용 함수를 최소화하는 가중치와 편향을 찾기 위해 최적화할 매개변수를 반복적으로 조정**하는 것입니다.\n",
    "- 이때 매개변수는 초기값에서 시작하여 경사 하강법을 통해 조정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de0e18-210b-4a4d-9fc3-2b862f05ca49",
   "metadata": {},
   "source": [
    "## 경사 하강법의 기본 과정\n",
    "1. 초기값 설정\n",
    "    - 가중치와 편향을 임의의 값으로 초기화합니다.\n",
    "2. 예측값 계산\n",
    "    - 초기 가중치와 편향을 사용하여 예측값을 계산합니다.\n",
    "3. 비용 함수 계산\n",
    "    - 예측값과 실제값을 비교하여 비용함수를 계산합니다.\n",
    "4. 기울기(gradient) 계산\n",
    "    - 비용 함수의 기울기를 계산합니다.\n",
    "5. 매개변수 업데이트\n",
    "    - 기울기를 사용하여 가중치와 편향을 업데이트합니다.\n",
    "6. 반복\n",
    "    - 2~5단계를 반복하여 **비용 함수를 최소화**하는 가중치와 편향을 찾습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb264657-f28b-4e5d-a416-acd334daf553",
   "metadata": {},
   "source": [
    "## 가중치와 편향을 조정하는 방법\n",
    "\n",
    "- batch gradient descent\n",
    "    - 전체 데이터셋을 사용하여 기울기를 계산합니다.\n",
    "- stochastic gradient descent\n",
    "    - 데이터셋을 일부분만 사용하여 기울기를 계산합니다.\n",
    "- mini-batch gradient descent\n",
    "    - batch와 stochastic의 장점을 결합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6128b-bf60-4a19-a27c-3643427ea662",
   "metadata": {},
   "source": [
    "## 경사 하강법의 주의할 점\n",
    "\n",
    "- 경사 하강법의 장점은 다른 최적화 알고리즘에 비해 구현이 간단하고 효율적이라는 점입니다. \n",
    "- 하지만 학습률(learning rate)을 적절히 설정하지 않으면 최적값에 수렴하지 못하거나 수렴하는 속도가 느려질 수 있습니다.\n",
    "    - 학습률이 너무 작으면 최소치에 가는 시간이 너무 오래 걸립니다.\n",
    "    - 학습률이 너무 크면 최소치에 접근하지 못하고 큰 이동을 해버리는 문제가 생깁니다.\n",
    "- 따라서 학습률을 조정하는 기법들이 중요하며, 이를 통해 경사 하강법의 성능을 향상시킬 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
